2025-05-02 04:33:02,669 INFO: 
                ____                _       _____  ____
               / __ ) ____ _ _____ (_)_____/ ___/ / __ \
              / __  |/ __ `// ___// // ___/\__ \ / /_/ /
             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/
            /_____/ \__,_//____//_/ \___//____//_/ |_|
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	BasicSR: 1.3.4.9
	PyTorch: 1.12.1
	TorchVision: 0.13.1
2025-05-02 04:33:02,669 INFO: 
  name: DRCT_SRx4
  model_type: DRCTModel
  scale: 4
  num_gpu: 1
  manual_seed: 0
  datasets:[
    test_1:[
      name: RescueNet-Test
      type: PairedImageDataset
      dataroot_gt: datasets/uploads/New_LR_dataset_512_test/RescueNet/HR/train-org-img
      dataroot_lq: datasets/uploads/New_LR_dataset_512_test/RescueNet/LR/train-org-img
      io_backend:[
        type: disk
      ]
      phase: test
      scale: 4
    ]
  ]
  network_g:[
    type: DRCT
    upscale: 4
    in_chans: 3
    img_size: 128
    window_size: 16
    compress_ratio: 3
    squeeze_factor: 30
    conv_scale: 0.01
    overlap_ratio: 0.5
    img_range: 1.0
    depths: [6, 6, 6, 6, 6, 6]
    embed_dim: 180
    num_heads: [6, 6, 6, 6, 6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffle
    resi_connection: 1conv
  ]
  path:[
    pretrain_network_g: experiments/train_DRCT_SRx4_RescueNet/models/net_g_latest.pth
    strict_load_g: True
    param_key_g: params_ema
    results_root: /teamspace/studios/this_studio/CSE498-CV-Project/DRCT/results/DRCT_SRx4
    log: /teamspace/studios/this_studio/CSE498-CV-Project/DRCT/results/DRCT_SRx4
    visualization: /teamspace/studios/this_studio/CSE498-CV-Project/DRCT/results/DRCT_SRx4/visualization
  ]
  val:[
    save_img: True
    suffix: None
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 4
        test_y_channel: True
      ]
      ssim:[
        type: calculate_ssim
        crop_border: 4
        test_y_channel: True
      ]
    ]
  ]
  dist: False
  rank: 0
  world_size: 1
  auto_resume: False
  is_train: False

2025-05-02 04:33:03,562 INFO: Dataset [PairedImageDataset] - RescueNet-Test is built.
2025-05-02 04:33:03,562 INFO: Number of test images in RescueNet-Test: 400
2025-05-02 04:33:03,803 INFO: Network [DRCT] is created.
2025-05-02 04:33:04,778 INFO: Network: DRCT, with parameters: 14,139,579
2025-05-02 04:33:04,778 INFO: DRCT(
  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RDG(
      (swin1): SwinTransformerBlock(
        dim=180, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=180, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=180, out_features=360, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=360, out_features=180, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin2): SwinTransformerBlock(
        dim=212, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2
        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=212, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=212, out_features=636, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=212, out_features=212, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=212, out_features=424, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=424, out_features=212, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin3): SwinTransformerBlock(
        dim=244, input_resolution=(128, 128), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=244, window_size=(16, 16), num_heads=2
          (qkv): Linear(in_features=244, out_features=732, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=244, out_features=244, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=244, out_features=488, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=488, out_features=244, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin4): SwinTransformerBlock(
        dim=276, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1
        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=276, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=276, out_features=828, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=276, out_features=276, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=276, out_features=276, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=276, out_features=276, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin5): SwinTransformerBlock(
        dim=308, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1
        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=308, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=308, out_features=924, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=308, out_features=308, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=308, out_features=308, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=308, out_features=308, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))
      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
      (pe): PatchEmbed()
      (pue): PatchUnEmbed()
    )
    (1): RDG(
      (swin1): SwinTransformerBlock(
        dim=180, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=180, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=180, out_features=360, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=360, out_features=180, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin2): SwinTransformerBlock(
        dim=212, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2
        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=212, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=212, out_features=636, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=212, out_features=212, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=212, out_features=424, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=424, out_features=212, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin3): SwinTransformerBlock(
        dim=244, input_resolution=(128, 128), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=244, window_size=(16, 16), num_heads=2
          (qkv): Linear(in_features=244, out_features=732, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=244, out_features=244, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=244, out_features=488, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=488, out_features=244, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin4): SwinTransformerBlock(
        dim=276, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1
        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=276, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=276, out_features=828, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=276, out_features=276, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=276, out_features=276, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=276, out_features=276, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin5): SwinTransformerBlock(
        dim=308, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1
        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=308, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=308, out_features=924, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=308, out_features=308, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=308, out_features=308, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=308, out_features=308, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))
      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
      (pe): PatchEmbed()
      (pue): PatchUnEmbed()
    )
    (2): RDG(
      (swin1): SwinTransformerBlock(
        dim=180, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=180, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=180, out_features=360, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=360, out_features=180, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin2): SwinTransformerBlock(
        dim=212, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2
        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=212, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=212, out_features=636, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=212, out_features=212, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=212, out_features=424, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=424, out_features=212, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin3): SwinTransformerBlock(
        dim=244, input_resolution=(128, 128), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=244, window_size=(16, 16), num_heads=2
          (qkv): Linear(in_features=244, out_features=732, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=244, out_features=244, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=244, out_features=488, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=488, out_features=244, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin4): SwinTransformerBlock(
        dim=276, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1
        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=276, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=276, out_features=828, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=276, out_features=276, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=276, out_features=276, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=276, out_features=276, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin5): SwinTransformerBlock(
        dim=308, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1
        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=308, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=308, out_features=924, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=308, out_features=308, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=308, out_features=308, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=308, out_features=308, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))
      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
      (pe): PatchEmbed()
      (pue): PatchUnEmbed()
    )
    (3): RDG(
      (swin1): SwinTransformerBlock(
        dim=180, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=180, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=180, out_features=360, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=360, out_features=180, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin2): SwinTransformerBlock(
        dim=212, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2
        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=212, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=212, out_features=636, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=212, out_features=212, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=212, out_features=424, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=424, out_features=212, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin3): SwinTransformerBlock(
        dim=244, input_resolution=(128, 128), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=244, window_size=(16, 16), num_heads=2
          (qkv): Linear(in_features=244, out_features=732, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=244, out_features=244, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=244, out_features=488, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=488, out_features=244, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin4): SwinTransformerBlock(
        dim=276, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1
        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=276, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=276, out_features=828, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=276, out_features=276, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=276, out_features=276, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=276, out_features=276, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin5): SwinTransformerBlock(
        dim=308, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1
        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=308, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=308, out_features=924, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=308, out_features=308, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=308, out_features=308, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=308, out_features=308, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))
      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
      (pe): PatchEmbed()
      (pue): PatchUnEmbed()
    )
    (4): RDG(
      (swin1): SwinTransformerBlock(
        dim=180, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=180, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=180, out_features=360, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=360, out_features=180, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin2): SwinTransformerBlock(
        dim=212, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2
        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=212, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=212, out_features=636, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=212, out_features=212, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=212, out_features=424, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=424, out_features=212, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin3): SwinTransformerBlock(
        dim=244, input_resolution=(128, 128), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=244, window_size=(16, 16), num_heads=2
          (qkv): Linear(in_features=244, out_features=732, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=244, out_features=244, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=244, out_features=488, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=488, out_features=244, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin4): SwinTransformerBlock(
        dim=276, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1
        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=276, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=276, out_features=828, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=276, out_features=276, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=276, out_features=276, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=276, out_features=276, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin5): SwinTransformerBlock(
        dim=308, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1
        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=308, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=308, out_features=924, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=308, out_features=308, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=308, out_features=308, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=308, out_features=308, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))
      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
      (pe): PatchEmbed()
      (pue): PatchUnEmbed()
    )
    (5): RDG(
      (swin1): SwinTransformerBlock(
        dim=180, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=180, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=180, out_features=360, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=360, out_features=180, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin2): SwinTransformerBlock(
        dim=212, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2
        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=212, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=212, out_features=636, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=212, out_features=212, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=212, out_features=424, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=424, out_features=212, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin3): SwinTransformerBlock(
        dim=244, input_resolution=(128, 128), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=244, window_size=(16, 16), num_heads=2
          (qkv): Linear(in_features=244, out_features=732, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=244, out_features=244, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=244, out_features=488, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=488, out_features=244, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin4): SwinTransformerBlock(
        dim=276, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1
        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=276, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=276, out_features=828, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=276, out_features=276, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=276, out_features=276, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=276, out_features=276, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin5): SwinTransformerBlock(
        dim=308, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1
        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=308, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=308, out_features=924, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=308, out_features=308, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=308, out_features=308, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=308, out_features=308, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))
      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
      (pe): PatchEmbed()
      (pue): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv_before_upsample): Sequential(
    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
    (2): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): PixelShuffle(upscale_factor=2)
  )
  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
2025-05-02 04:33:05,037 INFO: Loading DRCT model from experiments/train_DRCT_SRx4_RescueNet/models/net_g_latest.pth, with param key: [params_ema].
2025-05-02 04:33:05,153 INFO: Model [DRCTModel] is created.
2025-05-02 04:33:05,153 INFO: Testing RescueNet-Test...
2025-05-02 04:36:44,062 INFO: Validation RescueNet-Test
	 # psnr: 28.1793	Best: 28.1793 @ DRCT_SRx4 iter
	 # ssim: 0.7281	Best: 0.7281 @ DRCT_SRx4 iter

