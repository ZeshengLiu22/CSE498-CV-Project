2025-04-30 00:55:09,976 INFO: 
                ____                _       _____  ____
               / __ ) ____ _ _____ (_)_____/ ___/ / __ \
              / __  |/ __ `// ___// // ___/\__ \ / /_/ /
             / /_/ // /_/ /(__  )/ // /__ ___/ // _, _/
            /_____/ \__,_//____//_/ \___//____//_/ |_|
     ______                   __   __                 __      __
    / ____/____   ____   ____/ /  / /   __  __ _____ / /__   / /
   / / __ / __ \ / __ \ / __  /  / /   / / / // ___// //_/  / /
  / /_/ // /_/ // /_/ // /_/ /  / /___/ /_/ // /__ / /<    /_/
  \____/ \____/ \____/ \____/  /_____/\____/ \___//_/|_|  (_)
    
Version Information: 
	BasicSR: 1.3.4.9
	PyTorch: 1.12.1
	TorchVision: 0.13.1
2025-04-30 00:55:09,976 INFO: 
  name: train_DRCT_SRx4_from_scratch
  model_type: DRCTModel
  scale: 4
  num_gpu: 1
  manual_seed: 0
  datasets:[
    train:[
      name: FloodNet
      type: PairedImageDataset
      dataroot_gt: datasets/uploads/LR_dataset_512/FloodNet/HR/train-org-img
      dataroot_lq: datasets/uploads/LR_dataset_512/FloodNet/LR/train-org-img
      io_backend:[
        type: disk
      ]
      gt_size: 512
      use_hflip: True
      use_rot: True
      use_shuffle: True
      num_worker_per_gpu: 6
      batch_size_per_gpu: 1
      dataset_enlarge_ratio: 1
      prefetch_mode: None
      phase: train
      scale: 4
    ]
    val_1:[
      name: FloodNet
      type: PairedImageDataset
      dataroot_gt: datasets/uploads/LR_dataset_512/FloodNet/HR/train-org-img
      dataroot_lq: datasets/uploads/LR_dataset_512/FloodNet/LR/train-org-img
      io_backend:[
        type: disk
      ]
      phase: val
      scale: 4
    ]
  ]
  network_g:[
    type: DRCT
    upscale: 4
    in_chans: 3
    img_size: 128
    window_size: 16
    compress_ratio: 3
    squeeze_factor: 30
    conv_scale: 0.01
    overlap_ratio: 0.5
    img_range: 1.0
    depths: [6, 6, 6, 6, 6, 6]
    embed_dim: 180
    num_heads: [6, 6, 6, 6, 6, 6]
    mlp_ratio: 2
    upsampler: pixelshuffle
    resi_connection: 1conv
  ]
  path:[
    pretrain_network_g: None
    strict_load_g: True
    resume_state: None
    experiments_root: /teamspace/studios/this_studio/CSE498-CV-Project/DRCT/experiments/train_DRCT_SRx4_from_scratch
    models: /teamspace/studios/this_studio/CSE498-CV-Project/DRCT/experiments/train_DRCT_SRx4_from_scratch/models
    training_states: /teamspace/studios/this_studio/CSE498-CV-Project/DRCT/experiments/train_DRCT_SRx4_from_scratch/training_states
    log: /teamspace/studios/this_studio/CSE498-CV-Project/DRCT/experiments/train_DRCT_SRx4_from_scratch
    visualization: /teamspace/studios/this_studio/CSE498-CV-Project/DRCT/experiments/train_DRCT_SRx4_from_scratch/visualization
  ]
  train:[
    ema_decay: 0.999
    optim_g:[
      type: Adam
      lr: 0.0002
      weight_decay: 0
      betas: [0.9, 0.99]
    ]
    scheduler:[
      type: MultiStepLR
      milestones: [250000, 400000, 450000, 475000]
      gamma: 0.5
    ]
    total_iter: 500000
    warmup_iter: -1
    pixel_opt:[
      type: L1Loss
      loss_weight: 1.0
      reduction: mean
    ]
  ]
  val:[
    val_freq: 100.0
    save_img: False
    pbar: False
    metrics:[
      psnr:[
        type: calculate_psnr
        crop_border: 3
        test_y_channel: True
        better: higher
      ]
      ssim:[
        type: calculate_ssim
        crop_border: 3
        test_y_channel: True
        better: higher
      ]
    ]
  ]
  logger:[
    print_freq: 100
    save_checkpoint_freq: 5000.0
    use_tb_logger: True
    wandb:[
      project: None
      resume_id: None
    ]
  ]
  dist_params:[
    backend: nccl
    port: 29500
  ]
  dist: False
  rank: 0
  world_size: 1
  auto_resume: False
  is_train: True
  root_path: /teamspace/studios/this_studio/CSE498-CV-Project/DRCT

2025-04-30 00:55:10,420 INFO: Dataset [PairedImageDataset] - FloodNet is built.
2025-04-30 00:55:10,421 INFO: Training statistics:
	Number of train images: 398
	Dataset enlarge ratio: 1
	Batch size per gpu: 1
	World size (gpu number): 1
	Require iter number per epoch: 398
	Total epochs: 1257; iters: 500000.
2025-04-30 00:55:10,447 INFO: Dataset [PairedImageDataset] - FloodNet is built.
2025-04-30 00:55:10,447 INFO: Number of val images/folders in FloodNet: 398
2025-04-30 00:55:11,006 INFO: Network [DRCT] is created.
2025-04-30 00:55:13,138 INFO: Network: DRCT, with parameters: 14,139,579
2025-04-30 00:55:13,139 INFO: DRCT(
  (conv_first): Conv2d(3, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (patch_embed): PatchEmbed(
    (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  )
  (patch_unembed): PatchUnEmbed()
  (pos_drop): Dropout(p=0.0, inplace=False)
  (layers): ModuleList(
    (0): RDG(
      (swin1): SwinTransformerBlock(
        dim=180, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=180, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=180, out_features=360, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=360, out_features=180, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin2): SwinTransformerBlock(
        dim=212, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2
        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=212, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=212, out_features=636, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=212, out_features=212, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=212, out_features=424, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=424, out_features=212, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin3): SwinTransformerBlock(
        dim=244, input_resolution=(128, 128), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=244, window_size=(16, 16), num_heads=2
          (qkv): Linear(in_features=244, out_features=732, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=244, out_features=244, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=244, out_features=488, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=488, out_features=244, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin4): SwinTransformerBlock(
        dim=276, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1
        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=276, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=276, out_features=828, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=276, out_features=276, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=276, out_features=276, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=276, out_features=276, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin5): SwinTransformerBlock(
        dim=308, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1
        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=308, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=308, out_features=924, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=308, out_features=308, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): Identity()
        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=308, out_features=308, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=308, out_features=308, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))
      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
      (pe): PatchEmbed()
      (pue): PatchUnEmbed()
    )
    (1): RDG(
      (swin1): SwinTransformerBlock(
        dim=180, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=180, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=180, out_features=360, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=360, out_features=180, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin2): SwinTransformerBlock(
        dim=212, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2
        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=212, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=212, out_features=636, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=212, out_features=212, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=212, out_features=424, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=424, out_features=212, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin3): SwinTransformerBlock(
        dim=244, input_resolution=(128, 128), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=244, window_size=(16, 16), num_heads=2
          (qkv): Linear(in_features=244, out_features=732, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=244, out_features=244, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=244, out_features=488, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=488, out_features=244, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin4): SwinTransformerBlock(
        dim=276, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1
        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=276, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=276, out_features=828, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=276, out_features=276, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=276, out_features=276, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=276, out_features=276, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin5): SwinTransformerBlock(
        dim=308, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1
        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=308, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=308, out_features=924, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=308, out_features=308, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=308, out_features=308, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=308, out_features=308, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))
      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
      (pe): PatchEmbed()
      (pue): PatchUnEmbed()
    )
    (2): RDG(
      (swin1): SwinTransformerBlock(
        dim=180, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=180, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=180, out_features=360, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=360, out_features=180, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin2): SwinTransformerBlock(
        dim=212, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2
        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=212, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=212, out_features=636, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=212, out_features=212, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=212, out_features=424, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=424, out_features=212, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin3): SwinTransformerBlock(
        dim=244, input_resolution=(128, 128), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=244, window_size=(16, 16), num_heads=2
          (qkv): Linear(in_features=244, out_features=732, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=244, out_features=244, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=244, out_features=488, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=488, out_features=244, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin4): SwinTransformerBlock(
        dim=276, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1
        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=276, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=276, out_features=828, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=276, out_features=276, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=276, out_features=276, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=276, out_features=276, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin5): SwinTransformerBlock(
        dim=308, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1
        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=308, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=308, out_features=924, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=308, out_features=308, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=308, out_features=308, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=308, out_features=308, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))
      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
      (pe): PatchEmbed()
      (pue): PatchUnEmbed()
    )
    (3): RDG(
      (swin1): SwinTransformerBlock(
        dim=180, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=180, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=180, out_features=360, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=360, out_features=180, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin2): SwinTransformerBlock(
        dim=212, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2
        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=212, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=212, out_features=636, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=212, out_features=212, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=212, out_features=424, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=424, out_features=212, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin3): SwinTransformerBlock(
        dim=244, input_resolution=(128, 128), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=244, window_size=(16, 16), num_heads=2
          (qkv): Linear(in_features=244, out_features=732, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=244, out_features=244, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=244, out_features=488, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=488, out_features=244, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin4): SwinTransformerBlock(
        dim=276, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1
        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=276, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=276, out_features=828, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=276, out_features=276, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=276, out_features=276, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=276, out_features=276, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin5): SwinTransformerBlock(
        dim=308, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1
        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=308, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=308, out_features=924, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=308, out_features=308, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=308, out_features=308, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=308, out_features=308, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))
      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
      (pe): PatchEmbed()
      (pue): PatchUnEmbed()
    )
    (4): RDG(
      (swin1): SwinTransformerBlock(
        dim=180, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=180, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=180, out_features=360, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=360, out_features=180, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin2): SwinTransformerBlock(
        dim=212, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2
        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=212, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=212, out_features=636, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=212, out_features=212, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=212, out_features=424, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=424, out_features=212, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin3): SwinTransformerBlock(
        dim=244, input_resolution=(128, 128), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=244, window_size=(16, 16), num_heads=2
          (qkv): Linear(in_features=244, out_features=732, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=244, out_features=244, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=244, out_features=488, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=488, out_features=244, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin4): SwinTransformerBlock(
        dim=276, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1
        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=276, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=276, out_features=828, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=276, out_features=276, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=276, out_features=276, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=276, out_features=276, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin5): SwinTransformerBlock(
        dim=308, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1
        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=308, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=308, out_features=924, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=308, out_features=308, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=308, out_features=308, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=308, out_features=308, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))
      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
      (pe): PatchEmbed()
      (pue): PatchUnEmbed()
    )
    (5): RDG(
      (swin1): SwinTransformerBlock(
        dim=180, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=180, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=180, out_features=540, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=180, out_features=180, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=180, out_features=360, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=360, out_features=180, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust1): Conv2d(180, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin2): SwinTransformerBlock(
        dim=212, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=8, mlp_ratio=2
        (norm1): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=212, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=212, out_features=636, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=212, out_features=212, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((212,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=212, out_features=424, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=424, out_features=212, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust2): Conv2d(212, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin3): SwinTransformerBlock(
        dim=244, input_resolution=(128, 128), num_heads=2, window_size=16, shift_size=0, mlp_ratio=2
        (norm1): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=244, window_size=(16, 16), num_heads=2
          (qkv): Linear(in_features=244, out_features=732, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=244, out_features=244, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((244,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=244, out_features=488, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=488, out_features=244, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust3): Conv2d(244, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin4): SwinTransformerBlock(
        dim=276, input_resolution=(128, 128), num_heads=6, window_size=16, shift_size=8, mlp_ratio=1
        (norm1): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=276, window_size=(16, 16), num_heads=6
          (qkv): Linear(in_features=276, out_features=828, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=276, out_features=276, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((276,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=276, out_features=276, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=276, out_features=276, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust4): Conv2d(276, 32, kernel_size=(1, 1), stride=(1, 1))
      (swin5): SwinTransformerBlock(
        dim=308, input_resolution=(128, 128), num_heads=4, window_size=16, shift_size=0, mlp_ratio=1
        (norm1): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (attn): WindowAttention(
          dim=308, window_size=(16, 16), num_heads=4
          (qkv): Linear(in_features=308, out_features=924, bias=True)
          (attn_drop): Dropout(p=0.0, inplace=False)
          (proj): Linear(in_features=308, out_features=308, bias=True)
          (proj_drop): Dropout(p=0.0, inplace=False)
          (softmax): Softmax(dim=-1)
        )
        (drop_path): DropPath()
        (norm2): LayerNorm((308,), eps=1e-05, elementwise_affine=True)
        (mlp): Mlp(
          (fc1): Linear(in_features=308, out_features=308, bias=True)
          (act): GELU(approximate=none)
          (fc2): Linear(in_features=308, out_features=308, bias=True)
          (drop): Dropout(p=0.0, inplace=False)
        )
      )
      (adjust5): Conv2d(308, 180, kernel_size=(1, 1), stride=(1, 1))
      (lrelu): LeakyReLU(negative_slope=0.2, inplace=True)
      (pe): PatchEmbed()
      (pue): PatchUnEmbed()
    )
  )
  (norm): LayerNorm((180,), eps=1e-05, elementwise_affine=True)
  (conv_after_body): Conv2d(180, 180, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
  (conv_before_upsample): Sequential(
    (0): Conv2d(180, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): LeakyReLU(negative_slope=0.01, inplace=True)
  )
  (upsample): Upsample(
    (0): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): PixelShuffle(upscale_factor=2)
    (2): Conv2d(64, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (3): PixelShuffle(upscale_factor=2)
  )
  (conv_last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
)
2025-04-30 00:55:13,142 INFO: Use Exponential Moving Average with decay: 0.999
2025-04-30 00:55:13,526 INFO: Network [DRCT] is created.
2025-04-30 00:55:13,641 INFO: Loss [L1Loss] is created.
2025-04-30 00:55:13,643 INFO: Model [DRCTModel] is created.
2025-04-30 00:55:13,820 INFO: Start training from epoch: 0, iter: 0
2025-04-30 00:55:46,999 INFO: [train..][epoch:  0, iter:     100, lr:(2.000e-04,)] [eta: 1 day, 13:14:08, time (data): 0.332 (0.005)] l_pix: 6.1481e-02 
2025-04-30 00:57:49,279 INFO: Validation FloodNet
	 # psnr: 17.6495	Best: 17.6495 @ 100 iter
	 # ssim: 0.3618	Best: 0.3618 @ 100 iter

2025-04-30 00:58:16,682 INFO: [train..][epoch:  0, iter:     200, lr:(2.000e-04,)] [eta: 5 days, 2:05:42, time (data): 0.303 (0.004)] l_pix: 7.0352e-02 
2025-04-30 00:59:23,317 INFO: Validation FloodNet
	 # psnr: 18.1024	Best: 18.1024 @ 200 iter
	 # ssim: 0.3998	Best: 0.3998 @ 200 iter

2025-04-30 00:59:50,731 INFO: [train..][epoch:  0, iter:     300, lr:(2.000e-04,)] [eta: 5 days, 4:53:09, time (data): 0.274 (0.002)] l_pix: 6.5826e-02 
2025-04-30 01:00:57,580 INFO: Validation FloodNet
	 # psnr: 18.5638	Best: 18.5638 @ 300 iter
	 # ssim: 0.4289	Best: 0.4289 @ 300 iter

2025-04-30 01:01:25,313 INFO: [train..][epoch:  1, iter:     400, lr:(2.000e-04,)] [eta: 5 days, 6:27:21, time (data): 0.276 (0.004)] l_pix: 6.7457e-02 
2025-04-30 01:02:32,174 INFO: Validation FloodNet
	 # psnr: 19.0020	Best: 19.0020 @ 400 iter
	 # ssim: 0.4493	Best: 0.4493 @ 400 iter

2025-04-30 01:02:59,521 INFO: [train..][epoch:  1, iter:     500, lr:(2.000e-04,)] [eta: 5 days, 7:17:09, time (data): 0.273 (0.002)] l_pix: 3.8197e-02 
2025-04-30 01:04:06,536 INFO: Validation FloodNet
	 # psnr: 19.4420	Best: 19.4420 @ 500 iter
	 # ssim: 0.4659	Best: 0.4659 @ 500 iter

2025-04-30 01:04:33,929 INFO: [train..][epoch:  1, iter:     600, lr:(2.000e-04,)] [eta: 5 days, 7:52:36, time (data): 0.274 (0.002)] l_pix: 6.3616e-02 
2025-04-30 01:05:41,580 INFO: Validation FloodNet
	 # psnr: 19.8527	Best: 19.8527 @ 600 iter
	 # ssim: 0.4789	Best: 0.4789 @ 600 iter

2025-04-30 01:06:08,949 INFO: [train..][epoch:  1, iter:     700, lr:(2.000e-04,)] [eta: 5 days, 8:24:45, time (data): 0.274 (0.002)] l_pix: 1.1478e-01 
2025-04-30 01:07:18,832 INFO: Validation FloodNet
	 # psnr: 20.1933	Best: 20.1933 @ 700 iter
	 # ssim: 0.4909	Best: 0.4909 @ 700 iter

2025-04-30 01:07:46,727 INFO: [train..][epoch:  2, iter:     800, lr:(2.000e-04,)] [eta: 5 days, 9:17:07, time (data): 0.276 (0.004)] l_pix: 7.5037e-02 
2025-04-30 01:08:58,648 INFO: Validation FloodNet
	 # psnr: 20.5060	Best: 20.5060 @ 800 iter
	 # ssim: 0.5014	Best: 0.5014 @ 800 iter

2025-04-30 01:09:26,180 INFO: [train..][epoch:  2, iter:     900, lr:(2.000e-04,)] [eta: 5 days, 10:12:59, time (data): 0.275 (0.002)] l_pix: 4.8749e-02 
2025-04-30 01:10:37,091 INFO: Validation FloodNet
	 # psnr: 20.8429	Best: 20.8429 @ 900 iter
	 # ssim: 0.5121	Best: 0.5121 @ 900 iter

